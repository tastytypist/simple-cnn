{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fade326f",
   "metadata": {},
   "source": [
    "# Tugas Besar IF4074 - Pembelajaran Mesin Lanjut\n",
    "# Implementasi Convolutional Neural Network\n",
    "\n",
    "# Simple CNN\n",
    "**Simple CNN** is a convolutional neural network implemented in Python and fine-tuned using backpropagation algorithm.\n",
    "\n",
    "## Setup\n",
    "Assuming you've installed the latest version of Python (if not, guides for it are widely available),\n",
    "1. ensure pip is installed by running `python -m ensurepip --upgrade`;\n",
    "2. install the Python dependencies by running `pip install -r requirements.txt`.\n",
    "\n",
    "## Contribution (Milestone 1)\n",
    "| NIM      | Name                   | Contribution(s)                                                       |\n",
    "|----------|------------------------|-----------------------------------------------------------------------|\n",
    "| 13520041 | Ilham Pratama          | Dataset handling; Detector, Pooling, Dense, and Flatten layer; Report |\n",
    "| 13520042 | Jeremy S.O.N. Simbolon | Class model; Convolutional layer; Report                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642a8a3",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:04:53.241130300Z",
     "start_time": "2023-10-05T11:04:52.944944900Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import cv2\n",
    "import jsonpickle\n",
    "import jsonpickle.ext.numpy\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad81320",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d02ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T11:04:53.253382100Z",
     "start_time": "2023-10-05T11:04:53.246131700Z"
    }
   },
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    \"\"\"\n",
    "    Module related utility functions.\n",
    "\n",
    "    This class is used to prepare the image dataset for the CNN model. In\n",
    "    addition, this class is also used to save and load the CNN model.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset(dataset_path: str) -> tuple[npt.NDArray, npt.NDArray, dict]:\n",
    "        \"\"\"\n",
    "        Preprocess the dataset and return useful information for further processing.\n",
    "\n",
    "        :param dataset_path: A string representation of the path pointing to\n",
    "                             the dataset.\n",
    "        :return: A tuple consisted of an ndarray of dataset image path, an\n",
    "                 ndarray of image labels, and a dictionary that maps class\n",
    "                 labels to folder name.\n",
    "        \"\"\"\n",
    "        folder_list = sorted(os.listdir(dataset_path))\n",
    "        image_path = []\n",
    "        image_label = np.array([], dtype=np.int16)\n",
    "        image_dictionary = {}\n",
    "        for i, folder_name in enumerate(folder_list):\n",
    "            class_folder_path = os.path.join(dataset_path, folder_name)\n",
    "            list_image_name = sorted(os.listdir(class_folder_path))\n",
    "            temp_folder_path = [os.path.join(class_folder_path, image_name) for image_name in list_image_name]\n",
    "\n",
    "            image_path += temp_folder_path\n",
    "            temp_class_label = np.full(len(list_image_name), i, dtype=np.int16)\n",
    "            image_label = np.concatenate((image_label, temp_class_label), axis=0)\n",
    "            image_dictionary[str(i)] = folder_name\n",
    "\n",
    "        return np.asarray(image_path), image_label, image_dictionary\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_image_to_matrix(path: npt.NDArray) -> npt.NDArray:\n",
    "        \"\"\"\n",
    "        Convert the image dataset into a list of ndarray.\n",
    "\n",
    "        Each ndarray is an RGB representation of each image in the dataset.\n",
    "\n",
    "        :param path: An ndarray of string representation of the path pointing\n",
    "                     to each image entry in the dataset.\n",
    "        :return: A list of ndarray representation of the image in the dataset.\n",
    "        \"\"\"\n",
    "        list_of_image_matrix = []\n",
    "        size = (256, 256)\n",
    "\n",
    "        for file_img in path:\n",
    "            image = cv2.imread(file_img, 1)\n",
    "            matrix = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            matrix = cv2.resize(matrix, size)\n",
    "            list_of_image_matrix.append(matrix)\n",
    "\n",
    "        return np.array(list_of_image_matrix)\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(model_object: \"Model\", file_name: str = \"model.json\") -> None:\n",
    "        jsonpickle.ext.numpy.register_handlers()\n",
    "        with open(file_name, \"w\") as file:\n",
    "            json = jsonpickle.encode(model_object, indent=4)\n",
    "            file.write(json)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(file_name: str = \"model.json\") -> \"Model\":\n",
    "        jsonpickle.ext.numpy.register_handlers()\n",
    "        with open(file_name, \"r\") as file:\n",
    "            json = file.read()\n",
    "            return jsonpickle.decode(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b7f0f7",
   "metadata": {},
   "source": [
    "### Model Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9981df315bc56c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:04:53.315203200Z",
     "start_time": "2023-10-05T11:04:53.302381400Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"\n",
    "    The convolutional neural network model used to classify images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Instantiate the convolutional neural network model.\n",
    "        \"\"\"\n",
    "        self._layers = []\n",
    "        self._result = []\n",
    "\n",
    "    class Layer:\n",
    "        \"\"\"\n",
    "        Base representation of the layer used as part of the convolutional\n",
    "        neural network architecture.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, name) -> None:\n",
    "            \"\"\"\n",
    "            Instantiate the base layer.\n",
    "\n",
    "            :param name: Name of the layer.\n",
    "            \"\"\"\n",
    "            self._name = name\n",
    "\n",
    "        def feed_forward(self) -> None:\n",
    "            \"\"\"Indicate the forward propagation is being performed.\"\"\"\n",
    "            print(f\"Performing feed forward on {self._name} layer...\")\n",
    "            print()\n",
    "\n",
    "    class ConvolutionLayer(Layer):\n",
    "        \"\"\"\n",
    "        The convolutional layer in convolutional neural network.\n",
    "\n",
    "        This class is inherited from the ``Layer`` class. This layer is used\n",
    "        to perform the convolution operation on the input weights.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(\n",
    "            self,\n",
    "            filter_count: int,\n",
    "            filter_size: tuple[int, int] = (32, 32),\n",
    "            padding_size: int = 0,\n",
    "            stride_size: tuple[int, int] = (1, 1),\n",
    "        ) -> None:\n",
    "            \"\"\"\n",
    "            Instantiate the convolutional layer.\n",
    "\n",
    "            :param filter_count: An integer specifying the amount of feature\n",
    "                                 to be extracted in the form of the amount of\n",
    "                                 filters.\n",
    "            :param filter_size: A tuple of two integers specifying the height\n",
    "                                and width of the convolution filter.\n",
    "            :param padding_size: An integer specifying the dimension of 0's to\n",
    "                                 be added around the weight.\n",
    "            :param stride_size: A tuple of two integers specifying the pixel\n",
    "                                step size along the height and width of the\n",
    "                                input weight.\n",
    "            \"\"\"\n",
    "            super().__init__(\"convolution\")\n",
    "            self._filter_count = filter_count\n",
    "            self._filter_dimension = 0\n",
    "            self._filter_height, self._filter_width = filter_size\n",
    "            self._filter_weights = None\n",
    "            self._padding_size = padding_size\n",
    "            self._stride_height, self._stride_width = stride_size\n",
    "            self._output_height = 0\n",
    "            self._output_width = 0\n",
    "            self._weight_dimension = 0\n",
    "            self._weight_height = 0\n",
    "            self._weight_width = 0\n",
    "            self._biases = None\n",
    "\n",
    "        def _pad_weights(\n",
    "            self,\n",
    "            weights: npt.NDArray[npt.NDArray[npt.NDArray[float]]],\n",
    "            padding_size: int,\n",
    "        ) -> npt.NDArray[npt.NDArray[npt.NDArray[float]]]:\n",
    "            \"\"\"\n",
    "            Pad the specified weights with 0's around it.\n",
    "\n",
    "            :param weights: The ndarray of weights to be padded with 0's.\n",
    "            :param padding_size: An integer specifying the dimension of 0's to\n",
    "                                 be added around the weight.\n",
    "            :return: An ndarray of weights padded with 0's.\n",
    "            \"\"\"\n",
    "            self._weight_dimension = len(weights)\n",
    "\n",
    "            self._weight_height = (weight_height := len(weights[0])) + 2 * padding_size\n",
    "            self._weight_width = (weight_width := len(weights[0][0])) + 2 * padding_size\n",
    "\n",
    "            padded_weights = [\n",
    "                [\n",
    "                    [\n",
    "                        weights[i][j - padding_size][k - padding_size]\n",
    "                        if padding_size <= j < weight_height + padding_size\n",
    "                        or padding_size <= k < weight_width + padding_size\n",
    "                        else 0.0\n",
    "                        for k in range(self._weight_width)\n",
    "                    ]\n",
    "                    for j in range(self._weight_height)\n",
    "                ]\n",
    "                for i in range(self._weight_dimension)\n",
    "            ]\n",
    "\n",
    "            return np.array(padded_weights)\n",
    "\n",
    "        def convolute(\n",
    "            self,\n",
    "            weights: npt.NDArray[npt.NDArray[npt.NDArray[float]]],\n",
    "        ) -> npt.NDArray[npt.NDArray[npt.NDArray[float]]]:\n",
    "            \"\"\"\n",
    "            Perform the convolution operation on the input weights.\n",
    "\n",
    "            :param weights: An ndarray of input weights.\n",
    "            :return: An ndarray of features extracted from the weights.\n",
    "            \"\"\"\n",
    "            self._filter_dimension = len(weights)\n",
    "            self._output_height = (\n",
    "                math.ceil((len(weights[0]) - self._filter_height + 2 * self._padding_size) / self._stride_height) + 1\n",
    "            )\n",
    "            self._output_width = (\n",
    "                math.ceil((len(weights[0][0]) - self._filter_width + 2 * self._padding_size) / self._stride_width) + 1\n",
    "            )\n",
    "\n",
    "            if self._filter_weights is None:\n",
    "                self._filter_weights = np.random.rand(\n",
    "                    self._filter_count,\n",
    "                    self._filter_dimension,\n",
    "                    self._filter_height,\n",
    "                    self._filter_width,\n",
    "                )\n",
    "            if self._biases is None:\n",
    "                self._biases = np.random.rand(self._filter_count, self._output_height, self._output_width)\n",
    "\n",
    "            feature_maps = np.copy(self._biases)\n",
    "            weights = self._pad_weights(weights, self._padding_size)\n",
    "            for i in range(self._filter_count):\n",
    "                for j in range(0, self._weight_height - self._filter_height + 1, self._stride_height):\n",
    "                    for k in range(0, self._weight_width - self._filter_width + 1, self._stride_width):\n",
    "                        for l in range(self._filter_dimension):\n",
    "                            field = weights[l, j : j + self._filter_height, k : k + self._filter_width]\n",
    "                            feature = field * self._filter_weights[i][l]\n",
    "                            feature_maps[i][j][k] += np.sum(feature)\n",
    "            return feature_maps\n",
    "\n",
    "        def feed_forward(\n",
    "            self, weights: npt.NDArray[npt.NDArray[npt.NDArray[float]]]\n",
    "        ) -> npt.NDArray[npt.NDArray[npt.NDArray[float]]]:\n",
    "            \"\"\"\n",
    "            Indicate and perform the convolution process on the input weights.\n",
    "\n",
    "            :param weights: The ndarray of weights to be convoluted.\n",
    "            :return: An ndarray of convoluted weights.\n",
    "            \"\"\"\n",
    "            super().feed_forward()\n",
    "            result = self.convolute(weights)\n",
    "            print(\"Convolution result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    class DetectorLayer(Layer):\n",
    "        \"\"\"\n",
    "        The detector layer in convolutional neural network.\n",
    "\n",
    "        This class is inherited from the ``Layer`` class. This layer is used to\n",
    "        introduce non-linearity to the learning process using the reLU\n",
    "        activation function.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self) -> None:\n",
    "            \"\"\"Instantiate the detector layer.\"\"\"\n",
    "            super().__init__(\"detector\")\n",
    "\n",
    "        @staticmethod\n",
    "        def detect(feature: npt.NDArray) -> npt.NDArray:\n",
    "            \"\"\"\n",
    "            Apply the reLU activation function on the input weights.\n",
    "\n",
    "            :param feature: An ndarray of input weights.\n",
    "            :return: An ndarray of weights on which the reLU function has been\n",
    "                     applied.\n",
    "            \"\"\"\n",
    "            return np.maximum(feature, 0)\n",
    "\n",
    "        def feed_forward(self, feature: npt.NDArray) -> npt.NDArray:\n",
    "            \"\"\"\n",
    "            Indicate and perform the detector process on the input weights.\n",
    "\n",
    "            :param feature: The ndarray of weights on which reLU function is\n",
    "                            to be applied.\n",
    "            :return: An ndarray of activated weights.\n",
    "            \"\"\"\n",
    "            super().feed_forward()\n",
    "            result = self.detect(feature)\n",
    "            print(\"Detector result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    class PoolingLayer(Layer):\n",
    "        \"\"\"\n",
    "        The pooling layer in convolutional neural network.\n",
    "\n",
    "        This class is inherited from the ``Layer`` class. This layer is used to\n",
    "        down-sample the input weights according to the specified pooling\n",
    "        operation.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, filter_size: int, stride_size: int, mode: str = \"max\") -> None:\n",
    "            \"\"\"\n",
    "            Instantiate the pooling layer.\n",
    "\n",
    "            :param filter_size: An integer specifying the dimension of the\n",
    "                                pooling window.\n",
    "            :param stride_size: An integer specifying the pixel step size along\n",
    "                                the height and width of the input weight.\n",
    "            :param mode: A string specifying the preferred pooling operation.\n",
    "                         Must either be ``average`` or ``max``.\n",
    "            \"\"\"\n",
    "            super().__init__(\"pooling\")\n",
    "            self._filter_size = filter_size\n",
    "            self._stride_size = stride_size\n",
    "            self._mode = mode\n",
    "\n",
    "        def average(self, input_matrix: npt.NDArray, d: int, h: int, w: int) -> float:\n",
    "            \"\"\"\n",
    "            Take the average of the input values over the pooling window.\n",
    "\n",
    "            :param input_matrix: The ndarray of weights on which the operation\n",
    "                                 is applied.\n",
    "            :param d: An integer specifying the depth location of the pooling\n",
    "                      window.\n",
    "            :param h: An integer specifying the height location of the pooling\n",
    "                      window.\n",
    "            :param w: An integer specifying the width location of the pooling\n",
    "                      window.\n",
    "            :return: The average of the input values.\n",
    "            \"\"\"\n",
    "            h_start = h * self._stride_size\n",
    "            w_start = w * self._stride_size\n",
    "            h_end = h_start + self._filter_size\n",
    "            w_end = w_start + self._filter_size\n",
    "            return np.average(input_matrix[d, h_start:h_end, w_start:w_end])\n",
    "\n",
    "        def max(self, input_matrix: npt.NDArray, d: int, h: int, w: int) -> float:\n",
    "            \"\"\"\n",
    "            Take the maximum of the input values over the pooling window.\n",
    "\n",
    "            :param input_matrix: The ndarray of weights on which the operation\n",
    "                                 is applied.\n",
    "            :param d: An integer specifying the depth location of the pooling\n",
    "                      window.\n",
    "            :param h: An integer specifying the height location of the pooling\n",
    "                      window.\n",
    "            :param w: An integer specifying the width location of the pooling\n",
    "                      window.\n",
    "            :return: The maximum of the input values.\n",
    "            \"\"\"\n",
    "            h_start = h * self._stride_size\n",
    "            w_start = w * self._stride_size\n",
    "            h_end = h_start + self._filter_size\n",
    "            w_end = w_start + self._filter_size\n",
    "            return np.max(input_matrix[d, h_start:h_end, w_start:w_end])\n",
    "\n",
    "        def pool(self, input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            \"\"\"\n",
    "            Perform the pooling operation on the input weights.\n",
    "\n",
    "            :param input_matrix: An ndarray of input weights.\n",
    "            :return: An ndarray of down-sampled weights.\n",
    "            \"\"\"\n",
    "            depth, height, width = input_matrix.shape\n",
    "            filter_height = (height - self._filter_size) // self._stride_size + 1\n",
    "            filter_width = (width - self._filter_size) // self._stride_size + 1\n",
    "            pooled = np.zeros([depth, filter_height, filter_width], dtype=np.double)\n",
    "            for d in range(0, depth):\n",
    "                for h in range(0, filter_height):\n",
    "                    for w in range(0, filter_width):\n",
    "                        if self._mode == \"average\":\n",
    "                            pooled[d, h, w] = self.average(input_matrix, d, h, w)\n",
    "                        elif self._mode == \"max\":\n",
    "                            pooled[d, h, w] = self.max(input_matrix, d, h, w)\n",
    "            return pooled\n",
    "\n",
    "        def feed_forward(self, input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            \"\"\"\n",
    "            Indicate and perform the pooling operation on the input weights.\n",
    "\n",
    "            :param input_matrix: An ndarray of input weights.\n",
    "            :return: An ndarray of down-sampled weights.\n",
    "            \"\"\"\n",
    "            super().feed_forward()\n",
    "            result = self.pool(input_matrix)\n",
    "            print(\"Pooling result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    class DenseLayer(Layer):\n",
    "        \"\"\"\n",
    "        The dense layer in convolutional neural network.\n",
    "\n",
    "        This class is inherited from the ``Layer`` class. This layer is used to\n",
    "        abstractly represent the input data using its weights.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, unit_count: int, activation: str = \"sigmoid\") -> None:\n",
    "            \"\"\"\n",
    "            Instantiate the dense layer.\n",
    "\n",
    "            :param unit_count: An integer specifying the dimension of the\n",
    "                               output space.\n",
    "            :param activation: The activation function to be applied to each\n",
    "                               node. Must either be ``sigmoid`` or ``relu``.\n",
    "            \"\"\"\n",
    "            super().__init__(\"dense\")\n",
    "            self._unit_count = unit_count\n",
    "            self._activation = activation\n",
    "            self._bias = np.zeros(unit_count)\n",
    "            self._weight = np.random.randn(unit_count)\n",
    "\n",
    "        def dense(self, input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            \"\"\"\n",
    "            Perform the linear combination and activation of the input weights\n",
    "            using the layer's weights.\n",
    "\n",
    "            :param input_matrix: An ndarray of input weights.\n",
    "            :return: An ndarray of linearly-combined and activated weights.\n",
    "            \"\"\"\n",
    "            result = np.zeros(self._unit_count)\n",
    "\n",
    "            for i in range(self._unit_count):\n",
    "                input_weight = np.sum(self._weight[i] * input_matrix)\n",
    "                result[i] = input_weight + self._bias[i]\n",
    "\n",
    "            if self._activation == \"sigmoid\":\n",
    "                return expit(result)\n",
    "            elif self._activation == \"relu\":\n",
    "                return np.maximum(result, 0)\n",
    "\n",
    "        def feed_forward(self, input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            \"\"\"\n",
    "            Indicate and perform the linear combination and activation of the\n",
    "            input weights using the layer's weights.\n",
    "\n",
    "            :param input_matrix: An ndarray of input weights.\n",
    "            :return: An ndarray of linearly-combined and activated weights.\n",
    "            \"\"\"\n",
    "            super().feed_forward()\n",
    "            result = self.dense(input_matrix)\n",
    "            print(\"Dense result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    class FlattenLayer(Layer):\n",
    "        \"\"\"\n",
    "        The flatten layer in convolutional neural network.\n",
    "\n",
    "        This class is inherited from the ``Layer`` class. This layer is used to\n",
    "        flatten the input weights.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self) -> None:\n",
    "            \"\"\"Instantiate the flatten layer.\"\"\"\n",
    "            super().__init__(\"flatten\")\n",
    "\n",
    "        @staticmethod\n",
    "        def flatten(input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            \"\"\"\n",
    "            Perform the flatten operation on the input weights.\n",
    "\n",
    "            :param input_matrix: An ndarray of input weights.\n",
    "            :return: An ndarray of flatten weights.\n",
    "            \"\"\"\n",
    "            return input_matrix.flatten()\n",
    "\n",
    "        def feed_forward(self, input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            \"\"\"\n",
    "            Indicate and perform the flatten operation on the input weights.\n",
    "\n",
    "            :param input_matrix: An ndarray of input weights.\n",
    "            :return: An ndarray of flatten weights.\n",
    "            \"\"\"\n",
    "            super().feed_forward()\n",
    "            result = self.flatten(input_matrix)\n",
    "            print(\"Flatten result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    def add_layer(self, name: str, **kwargs: Any) -> None:\n",
    "        \"\"\"\n",
    "        Sequentially add the specified layer into the model.\n",
    "\n",
    "        :param name: A string representation of the layer to be added.\n",
    "        :param kwargs: Layer-related parameters in the form of key-value pairs.\n",
    "        \"\"\"\n",
    "        match name:\n",
    "            case \"convolution\":\n",
    "                self._layers.append(self.ConvolutionLayer(**kwargs))\n",
    "            case \"detector\":\n",
    "                self._layers.append(self.DetectorLayer())\n",
    "            case \"pooling\":\n",
    "                self._layers.append(self.PoolingLayer(**kwargs))\n",
    "            case \"dense\":\n",
    "                self._layers.append(self.DenseLayer(**kwargs))\n",
    "            case \"flatten\":\n",
    "                self._layers.append(self.FlattenLayer())\n",
    "\n",
    "    def forward_propagate(self, tensor: npt.NDArray) -> None:\n",
    "        \"\"\"\n",
    "        Indicate and perform the forward propagation operation on the model.\n",
    "\n",
    "        :param tensor: An ndarray of input weights representing the input\n",
    "                       pictures.\n",
    "        \"\"\"\n",
    "        for layer in self._layers:\n",
    "            tensor = layer.feed_forward(tensor)\n",
    "        print(\"Forward propagation result: \")\n",
    "        print(tensor)\n",
    "        self._result = tensor\n",
    "\n",
    "    def backward_propagate(self) -> None:\n",
    "        \"\"\"\n",
    "        Indicate and perform the backward propagation operation on the model.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def train(self, tensor: npt.NDArray[npt.NDArray]) -> None:\n",
    "        \"\"\"\n",
    "        This is a docstring placeholder.\n",
    "\n",
    "        :param tensor: An ndarray of representations of the input pictures to\n",
    "                       be fed into the model.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6dd31",
   "metadata": {},
   "source": [
    "### Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80fb427e45bb865f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:05:10.033906700Z",
     "start_time": "2023-10-05T11:04:53.312209300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feed forward on convolution layer...\n",
      "Convolution result: \n",
      "[[[ 648.49656359  641.52144541  638.99898134 ...  614.39773912\n",
      "    612.05264008  615.96808925]\n",
      "  [ 640.2958566   636.21464776  637.14061266 ...  615.46199162\n",
      "    612.83096313  616.60636706]\n",
      "  [ 637.26780274  635.15181697  637.95385063 ...  616.28592164\n",
      "    613.84294571  616.46747929]\n",
      "  ...\n",
      "  [ 247.46409385  191.63659062  137.63907593 ...   38.20088444\n",
      "     73.84022579  199.50167162]\n",
      "  [ 196.17667191  118.69304054  138.57464835 ...   80.74233723\n",
      "     84.21460189  244.83939581]\n",
      "  [ 142.671394     62.25614926   86.21873602 ...   99.7036421\n",
      "     91.93258199  219.9353509 ]]\n",
      "\n",
      " [[ 977.5944704   965.87805988  959.96179834 ...  920.38347878\n",
      "    917.51781425  922.34268052]\n",
      "  [ 965.41419635  958.12757317  957.58488995 ...  923.71278104\n",
      "    920.56192325  924.49532705]\n",
      "  [ 959.53156334  954.97527866  956.81634506 ...  925.94677319\n",
      "    922.600966    926.264062  ]\n",
      "  ...\n",
      "  [ 425.86931094  317.51873983  194.59234257 ...   56.12594987\n",
      "    121.39709018  270.07390807]\n",
      "  [ 265.85756872  185.72323257  222.75521249 ...  104.82915455\n",
      "    126.30906475  348.08076425]\n",
      "  [ 257.11552414  141.73392567  157.19941867 ...  149.40894869\n",
      "    123.55138349  323.0577862 ]]\n",
      "\n",
      " [[ 836.52766145  824.3896049   818.89103371 ...  788.16271851\n",
      "    785.30028631  786.40679068]\n",
      "  [ 826.29348551  817.54718363  815.41861548 ...  789.72558072\n",
      "    787.17447514  787.82636728]\n",
      "  [ 821.82776451  815.85092281  816.48566387 ...  792.70768101\n",
      "    789.18273962  789.81193988]\n",
      "  ...\n",
      "  [ 376.32682688  269.76094454  188.12249641 ...   43.75208111\n",
      "     87.90359882  188.55739534]\n",
      "  [ 277.34725756  181.96824796  170.58442059 ...  100.51798791\n",
      "    100.6629149   272.98811252]\n",
      "  [ 227.07700267  116.54749923   94.30183561 ...  117.64827727\n",
      "     91.53859931  241.20476174]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 933.5194596   921.01795528  915.64947569 ...  877.33201304\n",
      "    873.62729939  878.65697645]\n",
      "  [ 919.71440655  911.85190309  912.47769677 ...  881.40428656\n",
      "    877.74824617  882.20043796]\n",
      "  [ 912.51857735  908.97624853  912.61046884 ...  882.64014767\n",
      "    878.38673832  883.63105873]\n",
      "  ...\n",
      "  [ 403.48429103  310.51645643  204.78219225 ...   42.78342806\n",
      "    143.95150565  243.20638591]\n",
      "  [ 296.11782577  204.86572995  155.23553312 ...   66.18453283\n",
      "    139.14213709  272.39649478]\n",
      "  [ 227.11965743  110.19502243  119.47250234 ...  128.36815789\n",
      "    146.64697958  292.55696043]]\n",
      "\n",
      " [[ 572.43226013  562.83272316  556.52046439 ...  533.07076941\n",
      "    530.16382331  529.59943148]\n",
      "  [ 562.7541962   555.114031    552.20663729 ...  535.9611911\n",
      "    532.53389947  531.9897889 ]\n",
      "  [ 557.10322642  550.28032411  549.97144817 ...  536.54291009\n",
      "    533.67806253  532.7869871 ]\n",
      "  ...\n",
      "  [ 253.2557415   210.69676178  179.07875641 ...   23.1058821\n",
      "     53.07933232  108.14665285]\n",
      "  [ 227.04120628  161.70289587  112.45850848 ...   33.1860327\n",
      "     56.29311063  116.83001225]\n",
      "  [ 197.96254617  101.31870571   55.62086526 ...   63.00672478\n",
      "     65.97379701  141.62467728]]\n",
      "\n",
      " [[1023.65109373 1013.57963176 1008.43319405 ...  965.86967568\n",
      "    963.67261886  972.24413028]\n",
      "  [1010.05162644 1005.2873469  1006.03241264 ...  969.86453203\n",
      "    967.14135262  975.42358634]\n",
      "  [1003.6478524  1002.25034503 1008.29621866 ...  971.22953781\n",
      "    968.49872281  976.0533622 ]\n",
      "  ...\n",
      "  [ 414.70653745  324.09065801  221.84101612 ...   58.48082177\n",
      "    180.2555664   316.29813181]\n",
      "  [ 310.24326541  207.01056547  182.33874571 ...  111.66563861\n",
      "    155.5425909   374.05510066]\n",
      "  [ 208.24604502   85.21953174  144.69249238 ...  152.81644892\n",
      "    157.62007931  383.56401745]]]\n",
      "\n",
      "Performing feed forward on detector layer...\n",
      "\n",
      "Detector result: \n",
      "[[[ 648.49656359  641.52144541  638.99898134 ...  614.39773912\n",
      "    612.05264008  615.96808925]\n",
      "  [ 640.2958566   636.21464776  637.14061266 ...  615.46199162\n",
      "    612.83096313  616.60636706]\n",
      "  [ 637.26780274  635.15181697  637.95385063 ...  616.28592164\n",
      "    613.84294571  616.46747929]\n",
      "  ...\n",
      "  [ 247.46409385  191.63659062  137.63907593 ...   38.20088444\n",
      "     73.84022579  199.50167162]\n",
      "  [ 196.17667191  118.69304054  138.57464835 ...   80.74233723\n",
      "     84.21460189  244.83939581]\n",
      "  [ 142.671394     62.25614926   86.21873602 ...   99.7036421\n",
      "     91.93258199  219.9353509 ]]\n",
      "\n",
      " [[ 977.5944704   965.87805988  959.96179834 ...  920.38347878\n",
      "    917.51781425  922.34268052]\n",
      "  [ 965.41419635  958.12757317  957.58488995 ...  923.71278104\n",
      "    920.56192325  924.49532705]\n",
      "  [ 959.53156334  954.97527866  956.81634506 ...  925.94677319\n",
      "    922.600966    926.264062  ]\n",
      "  ...\n",
      "  [ 425.86931094  317.51873983  194.59234257 ...   56.12594987\n",
      "    121.39709018  270.07390807]\n",
      "  [ 265.85756872  185.72323257  222.75521249 ...  104.82915455\n",
      "    126.30906475  348.08076425]\n",
      "  [ 257.11552414  141.73392567  157.19941867 ...  149.40894869\n",
      "    123.55138349  323.0577862 ]]\n",
      "\n",
      " [[ 836.52766145  824.3896049   818.89103371 ...  788.16271851\n",
      "    785.30028631  786.40679068]\n",
      "  [ 826.29348551  817.54718363  815.41861548 ...  789.72558072\n",
      "    787.17447514  787.82636728]\n",
      "  [ 821.82776451  815.85092281  816.48566387 ...  792.70768101\n",
      "    789.18273962  789.81193988]\n",
      "  ...\n",
      "  [ 376.32682688  269.76094454  188.12249641 ...   43.75208111\n",
      "     87.90359882  188.55739534]\n",
      "  [ 277.34725756  181.96824796  170.58442059 ...  100.51798791\n",
      "    100.6629149   272.98811252]\n",
      "  [ 227.07700267  116.54749923   94.30183561 ...  117.64827727\n",
      "     91.53859931  241.20476174]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 933.5194596   921.01795528  915.64947569 ...  877.33201304\n",
      "    873.62729939  878.65697645]\n",
      "  [ 919.71440655  911.85190309  912.47769677 ...  881.40428656\n",
      "    877.74824617  882.20043796]\n",
      "  [ 912.51857735  908.97624853  912.61046884 ...  882.64014767\n",
      "    878.38673832  883.63105873]\n",
      "  ...\n",
      "  [ 403.48429103  310.51645643  204.78219225 ...   42.78342806\n",
      "    143.95150565  243.20638591]\n",
      "  [ 296.11782577  204.86572995  155.23553312 ...   66.18453283\n",
      "    139.14213709  272.39649478]\n",
      "  [ 227.11965743  110.19502243  119.47250234 ...  128.36815789\n",
      "    146.64697958  292.55696043]]\n",
      "\n",
      " [[ 572.43226013  562.83272316  556.52046439 ...  533.07076941\n",
      "    530.16382331  529.59943148]\n",
      "  [ 562.7541962   555.114031    552.20663729 ...  535.9611911\n",
      "    532.53389947  531.9897889 ]\n",
      "  [ 557.10322642  550.28032411  549.97144817 ...  536.54291009\n",
      "    533.67806253  532.7869871 ]\n",
      "  ...\n",
      "  [ 253.2557415   210.69676178  179.07875641 ...   23.1058821\n",
      "     53.07933232  108.14665285]\n",
      "  [ 227.04120628  161.70289587  112.45850848 ...   33.1860327\n",
      "     56.29311063  116.83001225]\n",
      "  [ 197.96254617  101.31870571   55.62086526 ...   63.00672478\n",
      "     65.97379701  141.62467728]]\n",
      "\n",
      " [[1023.65109373 1013.57963176 1008.43319405 ...  965.86967568\n",
      "    963.67261886  972.24413028]\n",
      "  [1010.05162644 1005.2873469  1006.03241264 ...  969.86453203\n",
      "    967.14135262  975.42358634]\n",
      "  [1003.6478524  1002.25034503 1008.29621866 ...  971.22953781\n",
      "    968.49872281  976.0533622 ]\n",
      "  ...\n",
      "  [ 414.70653745  324.09065801  221.84101612 ...   58.48082177\n",
      "    180.2555664   316.29813181]\n",
      "  [ 310.24326541  207.01056547  182.33874571 ...  111.66563861\n",
      "    155.5425909   374.05510066]\n",
      "  [ 208.24604502   85.21953174  144.69249238 ...  152.81644892\n",
      "    157.62007931  383.56401745]]]\n",
      "\n",
      "Performing feed forward on pooling layer...\n",
      "Pooling result: \n",
      "[[[ 639.22684197  638.35006894  640.08524151 ...  618.29971482\n",
      "    617.41520486  615.53414039]\n",
      "  [ 638.5478396   640.75747962  641.65162115 ...  624.47506013\n",
      "    622.41249936  618.5737555 ]\n",
      "  [ 637.33655775  639.12511255  637.54404563 ...  626.8933524\n",
      "    624.22621097  618.82266859]\n",
      "  ...\n",
      "  [ 219.77494193  238.63548015  276.55415561 ...  190.20392103\n",
      "    120.54908235  103.15685087]\n",
      "  [ 294.80236842  224.9607942   199.69225855 ...  234.57627526\n",
      "    124.60586258   79.99075245]\n",
      "  [ 204.14510446  165.45273758  161.35995972 ...  189.63962359\n",
      "    121.60566047   63.26058924]]\n",
      "\n",
      " [[ 961.76490835  958.4109166   960.00118701 ...  927.56945846\n",
      "    926.05218562  923.61711883]\n",
      "  [ 958.79718585  961.2185553   962.77494567 ...  936.83693281\n",
      "    933.62109962  928.56192477]\n",
      "  [ 957.25618918  959.59791553  957.3685814  ...  940.64841655\n",
      "    937.04996845  929.5968756 ]\n",
      "  ...\n",
      "  [ 327.07167221  341.26042351  414.15700171 ...  270.44192649\n",
      "    180.09945381  157.39688958]\n",
      "  [ 430.83438342  341.6244286   309.94741477 ...  345.58821117\n",
      "    190.25111067  118.74382558]\n",
      "  [ 320.7240304   266.80035786  243.93068213 ...  282.75033965\n",
      "    190.52776908   98.54694917]]\n",
      "\n",
      " [[ 821.4702151   818.18670146  820.0130865  ...  793.56757222\n",
      "    791.03446779  789.68188726]\n",
      "  [ 819.27716531  820.65589502  822.13995665 ...  801.13746885\n",
      "    798.00056017  794.30959416]\n",
      "  [ 816.59205219  818.74290613  817.4716306  ...  803.99764091\n",
      "    800.18514036  794.90348522]\n",
      "  ...\n",
      "  [ 281.94365197  301.34705946  341.96716302 ...  245.66331582\n",
      "    175.96522128  122.17140279]\n",
      "  [ 372.1259968   304.56034449  256.91054091 ...  285.01164219\n",
      "    190.73608369   89.90445475]\n",
      "  [ 282.42874536  215.36103604  213.22846564 ...  226.86189874\n",
      "    180.76971039   83.92043208]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 916.48179908  913.68740502  915.55036945 ...  884.47283428\n",
      "    883.4581954   880.77902921]\n",
      "  [ 913.67718097  917.64535575  919.39619721 ...  892.92286841\n",
      "    890.14973338  885.33971504]\n",
      "  [ 913.23549391  916.45235812  913.9815241  ...  897.76817166\n",
      "    894.02702439  887.10448076]\n",
      "  ...\n",
      "  [ 292.6150697   338.16510985  406.81515306 ...  260.13159409\n",
      "    179.09887756  153.34177222]\n",
      "  [ 428.23753242  328.73361473  306.34456193 ...  338.8399426\n",
      "    183.61685847  110.62231077]\n",
      "  [ 317.17964395  242.43793588  244.50114635 ...  279.94031222\n",
      "    177.01002924   90.9327995 ]]\n",
      "\n",
      " [[ 557.6905901   553.31499212  553.5183997  ...  536.13419596\n",
      "    534.35078332  534.15300625]\n",
      "  [ 553.90460252  554.90743092  556.67214882 ...  541.54189279\n",
      "    538.77357536  537.03760828]\n",
      "  [ 553.71190653  554.85313193  554.16727053 ...  544.5685341\n",
      "    541.90578145  538.72302647]\n",
      "  ...\n",
      "  [ 166.75615323  189.56812618  240.29688245 ...  150.47963449\n",
      "    121.22385461   88.05196818]\n",
      "  [ 254.49137468  223.40830999  182.31904579 ...  208.36033509\n",
      "    142.27636394   59.09131861]\n",
      "  [ 218.79103682  154.96351366  149.96452848 ...  163.15982914\n",
      "    134.16102085   47.14008821]]\n",
      "\n",
      " [[1009.02552462 1007.14481899 1010.18366557 ...  974.75555632\n",
      "    974.39422093  970.42902689]\n",
      "  [1007.48847707 1012.03542974 1013.94295278 ...  984.09784843\n",
      "    981.79079215  975.39495372]\n",
      "  [1006.57489416 1009.86546267 1007.17788338 ...  989.23009338\n",
      "    985.37148155  976.62816901]\n",
      "  ...\n",
      "  [ 323.33492351  385.63899914  453.47922947 ...  284.75598666\n",
      "    185.11143634  172.58245217]\n",
      "  [ 470.27778993  351.16768894  334.90032193 ...  365.80686834\n",
      "    175.00167401  135.18909477]\n",
      "  [ 332.79087091  260.6664819   261.36706643 ...  310.51195747\n",
      "    167.9829332   108.38029501]]]\n",
      "\n",
      "Performing feed forward on flatten layer...\n",
      "\n",
      "Flatten result: \n",
      "[639.22684197 638.35006894 640.08524151 ... 310.51195747 167.9829332\n",
      " 108.38029501]\n",
      "\n",
      "Performing feed forward on dense layer...\n",
      "\n",
      "Dense result: \n",
      "[2.08602481e+08 0.00000000e+00 0.00000000e+00 1.48636618e+08\n",
      " 6.13986040e+06 3.06512965e+08 0.00000000e+00 0.00000000e+00]\n",
      "\n",
      "Performing feed forward on dense layer...\n",
      "\n",
      "Dense result: \n",
      "[1.]\n",
      "\n",
      "Forward propagation result: \n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "folder_path, class_label, class_dictionary = Utils.load_dataset(\"./dataset\")\n",
    "image_matrix = Utils.convert_image_to_matrix(folder_path)\n",
    "image_number = 0\n",
    "image_matrix = [image_matrix[image_number]]\n",
    "\n",
    "model = Model()\n",
    "model.add_layer(\n",
    "    \"convolution\",\n",
    "    filter_count=32,\n",
    "    filter_size=(3, 3),\n",
    "    padding_size=0,\n",
    "    stride_size=(1, 1),\n",
    ")\n",
    "model.add_layer(\"detector\")\n",
    "model.add_layer(\"pooling\", filter_size=3, stride_size=2, mode=\"average\")\n",
    "model.add_layer(\"flatten\")\n",
    "model.add_layer(\"dense\", unit_count=8, activation=\"relu\")\n",
    "model.add_layer(\"dense\", unit_count=1, activation=\"sigmoid\")\n",
    "model.forward_propagate(image_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
