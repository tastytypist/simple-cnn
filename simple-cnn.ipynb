{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fade326f",
   "metadata": {},
   "source": [
    "# Tugas Besar IF4074 - Bembelajaran Mesin Lanjut "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d470d47",
   "metadata": {},
   "source": [
    "## Anggota Kelompok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5a74c",
   "metadata": {},
   "source": [
    "1. Ilham Pratama (13520041)\n",
    "2. Jeremy S.O.N Simbolon (13520042)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7b5f0",
   "metadata": {},
   "source": [
    "## Kode Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642a8a3",
   "metadata": {},
   "source": [
    "### Import semua librry yang diperlukan dalam pengerjaan tugas ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T10:13:32.406023400Z",
     "start_time": "2023-09-18T10:13:32.246657900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad81320",
   "metadata": {},
   "source": [
    "### Kelas Utils, Kelas ini digunakan untuk me-<i>load</i> dataset dan dan mengubah gambar menjadi array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a5d02ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T10:13:32.416339700Z",
     "start_time": "2023-09-18T10:13:32.411004100Z"
    }
   },
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def load_dataset(dataset_path: str) -> tuple[npt.NDArray, npt.NDArray, dict]:\n",
    "        folder_list = sorted(os.listdir(dataset_path))\n",
    "        folder_path = []\n",
    "        class_label = np.array([], dtype=np.int16)\n",
    "        class_dictionary = {}\n",
    "        for i, folder_name in enumerate(folder_list):\n",
    "            class_folder_path = os.path.join(dataset_path, folder_name)\n",
    "            list_image_name = sorted(os.listdir(class_folder_path))\n",
    "            temp_folder_path = [\n",
    "                os.path.join(class_folder_path, image_name)\n",
    "                for image_name in list_image_name\n",
    "            ]\n",
    "\n",
    "            folder_path += temp_folder_path\n",
    "            temp_class_label = np.full(len(list_image_name), i, dtype=np.int16)\n",
    "            class_label = np.concatenate((class_label, temp_class_label), axis=0)\n",
    "            class_dictionary[str(i)] = folder_name\n",
    "\n",
    "        return np.asarray(folder_path), class_label, class_dictionary\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_image_to_matrix(folder_path: str) -> npt.NDArray:\n",
    "        list_of_image_matrix = []\n",
    "        size = (256, 256)\n",
    "\n",
    "        for file_img in folder_path:\n",
    "            image = cv2.imread(file_img, 1)\n",
    "            image_matrix = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image_matrix = cv2.resize(image_matrix, size)\n",
    "            list_of_image_matrix.append(image_matrix)\n",
    "            \n",
    "        return np.array(list_of_image_matrix)\n",
    "\n",
    "\n",
    "# For testing purposes\n",
    "# if __name__ == \"__main__\":\n",
    "#     folder_path, class_label, class_dictionary = Utils.load_dataset(\"./dataset\")\n",
    "#     print(Utils.convert_image_to_matrix(folder_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b7f0f7",
   "metadata": {},
   "source": [
    "### Class Model, kelas ini berisi semua layers, fungsi, dan prosedure yang digunakan untuk proses CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "a9981df315bc56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T10:13:32.450822700Z",
     "start_time": "2023-09-18T10:13:32.421344700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self) -> None:\n",
    "        self._layers = []\n",
    "        self.result = []\n",
    "\n",
    "    class Layer:\n",
    "        def __init__(self, name):\n",
    "            self.name = name\n",
    "\n",
    "        def feed_forward(self):\n",
    "            print(f\"Performing feed forward on {self.name} layer...\")\n",
    "            print()\n",
    "\n",
    "    class ConvolutionLayer(Layer):\n",
    "        def __init__(\n",
    "            self,\n",
    "            filter_size: list[tuple[int]],\n",
    "            padding_size: int,\n",
    "            stride_size: list[int],\n",
    "        ) -> None:\n",
    "            super().__init__(\"convolution\")\n",
    "            self._filter_weight = np.array(\n",
    "                [\n",
    "                    [\n",
    "                        [random.random() for _ in range(filter_size[i][1])]\n",
    "                        for _ in range(filter_size[i][0])\n",
    "                    ]\n",
    "                    for i in range(len(filter_size))\n",
    "                ]\n",
    "            )\n",
    "            self._padding_size = padding_size\n",
    "            self._stride_size = stride_size\n",
    "\n",
    "        @staticmethod\n",
    "        def _pad_weights(\n",
    "            weights: npt.NDArray[npt.NDArray[npt.NDArray[float]]],\n",
    "            padding_size: int,\n",
    "        ) -> npt.NDArray[npt.NDArray[npt.NDArray[float]]]:\n",
    "            padded_weights = []\n",
    "\n",
    "            for i in range(len(weights)):\n",
    "                weight_height = len(weights[i])\n",
    "                weight_width = len(weights[i][0])\n",
    "                padded_height = weight_height + 2 * padding_size\n",
    "                padded_width = weight_width + 2 * padding_size\n",
    "\n",
    "                new_weight = [\n",
    "                    [\n",
    "                        weights[i][j - padding_size][k - padding_size]\n",
    "                        if padding_size <= j < weight_height + padding_size\n",
    "                        or padding_size <= k < weight_width + padding_size\n",
    "                        else 0.0\n",
    "                        for k in range(padded_width)\n",
    "                    ]\n",
    "                    for j in range(padded_height)\n",
    "                ]\n",
    "\n",
    "                padded_weights.append(new_weight)\n",
    "\n",
    "            return np.array(padded_weights)\n",
    "\n",
    "        def convolute(\n",
    "            self,\n",
    "            weights: npt.NDArray[npt.NDArray[npt.NDArray[float]]],\n",
    "        ) -> npt.NDArray[npt.NDArray[npt.NDArray[float]]]:\n",
    "            feature_maps = []\n",
    "            print(\"Randomly initialised filter weight: \")\n",
    "            print(self._filter_weight)\n",
    "            print()\n",
    "            weights = self._pad_weights(weights, self._padding_size)\n",
    "            for i in range(len(weights)):\n",
    "                feature_map = []\n",
    "                for j in range(\n",
    "                    0,\n",
    "                    len(weights[i]) - len(self._filter_weight[i]) + 1,\n",
    "                    self._stride_size[i],\n",
    "                ):\n",
    "                    feature_row = []\n",
    "                    for k in range(\n",
    "                        0,\n",
    "                        len(weights[i][j]) - len(self._filter_weight[i][0]) + 1,\n",
    "                        self._stride_size[i],\n",
    "                    ):\n",
    "                        field = weights[\n",
    "                            i,\n",
    "                            j : j + len(self._filter_weight[i]),\n",
    "                            k : k + len(self._filter_weight[i][0]),\n",
    "                        ]\n",
    "                        feature = field * self._filter_weight[i]\n",
    "                        feature_row.append(np.sum(feature))\n",
    "                    feature_map.append(feature_row)\n",
    "                feature_maps.append(feature_map)\n",
    "            return np.array(feature_maps)\n",
    "\n",
    "        def feed_forward(\n",
    "            self, weights: npt.NDArray[npt.NDArray[npt.NDArray[float]]]\n",
    "        ) -> npt.NDArray[npt.NDArray[npt.NDArray[float]]]:\n",
    "            super().feed_forward()\n",
    "            result = self.convolute(weights)\n",
    "            print(\"Convolution result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    class DetectorLayer(Layer):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"detector\")\n",
    "\n",
    "        @staticmethod\n",
    "        def detect(feature: npt.NDArray) -> npt.NDArray:\n",
    "            return np.maximum(feature, 0)\n",
    "\n",
    "        def feed_forward(self, feature: npt.NDArray) -> npt.NDArray:\n",
    "            super().feed_forward()\n",
    "            result = self.detect(feature)\n",
    "            print(\"Detector result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    class PoolingLayer(Layer):\n",
    "        def __init__(\n",
    "            self, filter_size: int, stride_size: int, mode: str = \"max\"\n",
    "        ) -> None:\n",
    "            super().__init__(\"pooling\")\n",
    "            self.filter_size = filter_size\n",
    "            self.stride_size = stride_size\n",
    "            self.mode = mode\n",
    "\n",
    "        def average(\n",
    "            self, input_matrix: npt.NDArray, d: int, h: int, w: int\n",
    "        ) -> npt.NDArray:\n",
    "            h_start = h * self.stride_size\n",
    "            w_start = w * self.stride_size\n",
    "            h_end = h_start + self.filter_size\n",
    "            w_end = w_start + self.filter_size\n",
    "            return np.average(input_matrix[d, h_start:h_end, w_start:w_end])\n",
    "\n",
    "        def max(self, input_matrix: npt.NDArray, d: int, h: int, w: int) -> npt.NDArray:\n",
    "            h_start = h * self.stride_size\n",
    "            w_start = w * self.stride_size\n",
    "            h_end = h_start + self.filter_size\n",
    "            w_end = w_start + self.filter_size\n",
    "            return np.max(input_matrix[d, h_start:h_end, w_start:w_end])\n",
    "\n",
    "        def pool(self, input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            depth, height, width = input_matrix.shape\n",
    "            filter_height = (height - self.filter_size) // self.stride_size + 1\n",
    "            filter_width = (width - self.filter_size) // self.stride_size + 1\n",
    "            pooled = np.zeros([depth, filter_height, filter_width], dtype=np.double)\n",
    "            for d in range(0, depth):\n",
    "                for h in range(0, filter_height):\n",
    "                    for w in range(0, filter_width):\n",
    "                        if self.mode == \"average\":\n",
    "                            pooled[d, h, w] = self.average(input_matrix, d, h, w)\n",
    "                        elif self.mode == \"max\":\n",
    "                            pooled[d, h, w] = self.max(input_matrix, d, h, w)\n",
    "            return pooled\n",
    "\n",
    "        def feed_forward(self, input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            super().feed_forward()\n",
    "            result = self.pool(input_matrix)\n",
    "            print(\"Pooling result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    class DenseLayer(Layer):\n",
    "        def __init__(self, unit_count: int, activation: str = \"sigmoid\") -> None:\n",
    "            super().__init__(\"dense\")\n",
    "            self.unit_count = unit_count\n",
    "            self.activation = activation\n",
    "            self.bias = np.zeros(unit_count)\n",
    "            self.weight = np.random.randn(unit_count)\n",
    "\n",
    "        def dense(self, input_matrix: npt.NDArray) -> float:\n",
    "            result = np.zeros(self.unit_count)\n",
    "\n",
    "            for i in range(self.unit_count):\n",
    "                input_weight = np.sum(self.weight[i] * input_matrix)\n",
    "                result[i] = input_weight + self.bias[i]\n",
    "\n",
    "            if self.activation == \"sigmoid\":\n",
    "                return 1 / (1 + np.exp(-result))\n",
    "            elif self.activation == \"relu\":\n",
    "                return np.maximum(result, 0)\n",
    "\n",
    "        def feed_forward(self, input_matrix: npt.NDArray) -> float:\n",
    "            super().feed_forward()\n",
    "            result = self.dense(input_matrix)\n",
    "            print(\"Dense result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    class FlattenLayer(Layer):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"flatten\")\n",
    "\n",
    "        @staticmethod\n",
    "        def flatten(input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            return input_matrix.flatten()\n",
    "\n",
    "        def feed_forward(self, input_matrix: npt.NDArray) -> npt.NDArray:\n",
    "            super().feed_forward()\n",
    "            result = self.flatten(input_matrix)\n",
    "            print(\"Flatten result: \")\n",
    "            print(result)\n",
    "            print()\n",
    "            return result\n",
    "\n",
    "    def add_layer(self, name: str, **kwargs):\n",
    "        match name:\n",
    "            case \"convolution\":\n",
    "                self._layers.append(self.ConvolutionLayer(**kwargs))\n",
    "            case \"detector\":\n",
    "                self._layers.append(self.DetectorLayer())\n",
    "            case \"pooling\":\n",
    "                self._layers.append(self.PoolingLayer(**kwargs))\n",
    "            case \"dense\":\n",
    "                self._layers.append(self.DenseLayer(**kwargs))\n",
    "            case \"flatten\":\n",
    "                self._layers.append(self.FlattenLayer())\n",
    "\n",
    "    def feed_forward(self, tensor: npt.NDArray) -> None:\n",
    "        for layer in self._layers:\n",
    "            tensor = layer.feed_forward(tensor)\n",
    "        print(\"Feedforward result: \")\n",
    "        print(tensor)\n",
    "        self.result = tensor\n",
    "\n",
    "    def back_propagate(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6dd31",
   "metadata": {},
   "source": [
    "### Kode ini merupakan main program yang digunakan pada tugas ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "80fb427e45bb865f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T10:13:32.450822700Z",
     "start_time": "2023-09-18T10:13:32.442112300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feed forward on convolution layer...\n",
      "\n",
      "Randomly initialised filter weight: \n",
      "[[[0.40980417 0.42932282 0.02301019]\n",
      "  [0.38184355 0.71643347 0.56917264]\n",
      "  [0.0953937  0.78254084 0.34766899]]]\n",
      "\n",
      "Convolution result: \n",
      "[[[667.16115308 658.50597283 655.61613209 ... 629.38064987 625.57686601\n",
      "   628.57364597]\n",
      "  [657.52379749 651.83215989 652.91901318 ... 631.54677035 627.7429865\n",
      "   630.71675626]\n",
      "  [653.84374193 650.271887   653.34216468 ... 631.96706141 628.16327755\n",
      "   630.78937832]\n",
      "  ...\n",
      "  [278.29100207 218.42723524 149.17760919 ...  30.94743751  77.42794817\n",
      "   167.95259033]\n",
      "  [201.58156754 120.33195868 110.97319285 ...  47.43233879  93.4727082\n",
      "   183.29793075]\n",
      "  [157.8243867   86.9088789   89.89269475 ...  85.12772251 114.76629829\n",
      "   188.68871392]]]\n",
      "\n",
      "Performing feed forward on detector layer...\n",
      "\n",
      "Detector result: \n",
      "[[[667.16115308 658.50597283 655.61613209 ... 629.38064987 625.57686601\n",
      "   628.57364597]\n",
      "  [657.52379749 651.83215989 652.91901318 ... 631.54677035 627.7429865\n",
      "   630.71675626]\n",
      "  [653.84374193 650.271887   653.34216468 ... 631.96706141 628.16327755\n",
      "   630.78937832]\n",
      "  ...\n",
      "  [278.29100207 218.42723524 149.17760919 ...  30.94743751  77.42794817\n",
      "   167.95259033]\n",
      "  [201.58156754 120.33195868 110.97319285 ...  47.43233879  93.4727082\n",
      "   183.29793075]\n",
      "  [157.8243867   86.9088789   89.89269475 ...  85.12772251 114.76629829\n",
      "   188.68871392]]]\n",
      "\n",
      "Performing feed forward on pooling layer...\n",
      "\n",
      "Pooling result: \n",
      "[[[658.75577082 654.7183195  654.24185526 ... 631.72627786 628.56181818\n",
      "   628.15256368]\n",
      "  [653.36789658 652.09130619 654.27163369 ... 633.11494452 629.85502395\n",
      "   629.35309966]\n",
      "  [652.72594007 652.68098385 655.8346673  ... 634.46684752 631.08062749\n",
      "   630.34949279]\n",
      "  ...\n",
      "  [276.19271178 231.66759204 179.00520911 ...  35.55154604  61.35108228\n",
      "   133.62329455]\n",
      "  [204.65794088 149.72749899 147.94013269 ...  45.60466466  62.32010817\n",
      "   130.53779436]\n",
      "  [141.66169795 102.02668129 134.83555311 ...  74.24330195  85.19976695\n",
      "   145.05641279]]]\n",
      "\n",
      "Performing feed forward on dense layer...\n",
      "\n",
      "Dense result: \n",
      "[0.]\n",
      "\n",
      "Performing feed forward on flatten layer...\n",
      "\n",
      "Flatten result: \n",
      "[0.]\n",
      "\n",
      "Feedforward result: \n",
      "[0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pilha\\AppData\\Local\\Temp\\ipykernel_17736\\1715336039.py:184: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-result))\n"
     ]
    }
   ],
   "source": [
    "input_tensor = np.array(\n",
    "    [\n",
    "        [\n",
    "            [1, 2, 3, 4, 5, 6],\n",
    "            [7, 8, 9, 10, 11, 12],\n",
    "            [13, 14, 15, 16, 17, 18],\n",
    "            [19, 20, 21, 22, 23, 24],\n",
    "            [25, 26, 27, 28, 29, 30],\n",
    "            [31, 32, 33, 34, 35, 36],\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "#load dataset\n",
    "folder_path, class_label, class_dictionary = Utils.load_dataset(\"./dataset\")\n",
    "image_matrix = Utils.convert_image_to_matrix(folder_path)\n",
    "image_number = 0\n",
    "image_matrix_to_test = [image_matrix[image_number]]\n",
    "\n",
    "model = Model()\n",
    "model.add_layer(\"convolution\", filter_size=[(3, 3)], padding_size=0, stride_size=[1])\n",
    "model.add_layer(\"detector\")\n",
    "model.add_layer(\"pooling\", filter_size=2, stride_size=1, mode=\"average\")\n",
    "model.add_layer(\"dense\", unit_count=1, activation=\"sigmoid\")\n",
    "model.add_layer(\"flatten\")\n",
    "model.feed_forward(image_matrix_to_test)\n",
    "\n",
    "# belum tau benar atau salahnya\n",
    "# dest_class = folder_path[image_number].split(\"\\\\\")\n",
    "# dest_class = dest_class[-2]\n",
    "# if dest_class == 'bears':\n",
    "#     class_dictionary = {'0': 'pandas', '1': 'bears'}\n",
    "# else:\n",
    "#     class_dictionary = {'0': 'bears', '1': 'pandas'}\n",
    "\n",
    "# print(\"picture : \", folder_path[image_number])\n",
    "# # Jika mendekati 1 maka hasil prediksi hampir benar\n",
    "# result = 0 if model.result[0] < 0.5 else 1\n",
    "# print(\"prediction : \", class_dictionary[str(int(result))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
